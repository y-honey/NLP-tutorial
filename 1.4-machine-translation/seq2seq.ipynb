{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_Su6-OWedGRx"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from pickle import dump\n",
    "import pandas as pd\n",
    "from numpy import array\n",
    "from numpy.random import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow.keras.layers import Input ,LSTM, Embedding, Dense, TimeDistributed\n",
    "\n",
    "from tensorflow.keras.layers import RepeatVector, Bidirectional, Dropout\n",
    "\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "#from generate_phoneme import get_phoneme_list\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import numpy as np\n",
    "\n",
    "from numpy import argmax\n",
    "from tensorflow.keras.models import load_model,model_from_json\n",
    "import time\n",
    "from pickle import load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "sCpzQ2k2d7JD",
    "outputId": "d5063da8-2fd9-4a8d-ca7d-f8984d5a4e38"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "# Path to the data txt file on disk.\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D7gplBvjiGKz"
   },
   "outputs": [],
   "source": [
    "class LoadData():\n",
    "        \n",
    "    def load_data(self):\n",
    "        data_path = '/content/drive/My Drive/Projects/NLP-Notebooks/1.4-machine-translation/data/ben-eng/ben.txt'\n",
    "        file = open(data_path, encoding=\"utf8\")\n",
    "        lines = file.read().split('\\n')\n",
    "        input_target = list()\n",
    "        for line in lines:\n",
    "            try:\n",
    "                input_text, target_text,_ = line.split('\\t')\n",
    "                target_text = \"START \"+target_text+\" END\"\n",
    "                input_target.append([input_text, target_text])\n",
    "            except:\n",
    "                pass\n",
    "        df = pd.DataFrame(input_target, columns = [\"Input\",\"Target\"])\n",
    "        return input_target,df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EoN1Furqkguk"
   },
   "outputs": [],
   "source": [
    "class PreProcessing():\n",
    "    def __init__(self,dataset=None):\n",
    "        self.pairs = None\n",
    "        self.dataset = dataset\n",
    "        self.training_data = None\n",
    "        self.testing_data = None\n",
    "        \n",
    "    def tokenization(self,df):\n",
    "        df['Target'] = df['Target'].apply(lambda x : 'START '+ x + ' END')\n",
    "        self.input_max_length=max(df['Input'].apply(lambda x:len(x.split())))\n",
    "        self.target_max_length=max(df['Target'].apply(lambda x:len(x.split())))\n",
    "\n",
    "        all_input_words = list(set([word for sent in df[\"Input\"] for word in sent.split()]))\n",
    "        all_target_words = list(set([word for sent in df[\"Target\"] for word in sent.split()]))\n",
    "\n",
    "        self.input_vocab_size = len(all_input_words)\n",
    "        self.target_vocab_size = len(all_target_words)\n",
    "\n",
    "        self.input_token_index = dict([(word, i+1) for i, word in enumerate(all_input_words)])\n",
    "        self.target_token_index = dict([(word, i+1) for i, word in enumerate(all_target_words)])\n",
    "        self.reverse_input_index = dict((i, word) for word, i in self.input_token_index.items())\n",
    "        self.reverse_target_index = dict((i, word) for word, i in self.target_token_index.items())\n",
    "        x_train, x_test, y_train, y_test = train_test_split(df[\"Input\"], df[\"Target\"], test_size = 0.2,random_state=123)\n",
    "        return x_train, x_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "poERbb0vfiv8"
   },
   "outputs": [],
   "source": [
    "class DesignModel():\n",
    "    \n",
    "    def __init__(self,X_train,Y_train,X_test,Y_test,epochs,batch_size):\n",
    "        self.X_train = X_train\n",
    "        self.Y_train = Y_train\n",
    "        self.X_test = X_test\n",
    "        self.Y_test = Y_test\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "    \n",
    "    def generate_batch(self, X, y, max_length_src, max_length_tar,encoder_tokens, decoder_tokens,num_decoder_tokens, batch_size ):\n",
    "        ''' Generate a batch of data '''\n",
    "        while True:\n",
    "            for j in range(0, len(X), batch_size):\n",
    "                encoder_input_data = np.zeros((batch_size, max_length_src),dtype='float32')\n",
    "                decoder_input_data = np.zeros((batch_size, max_length_tar),dtype='float32')\n",
    "                decoder_target_data = np.zeros((batch_size, max_length_tar, num_decoder_tokens),dtype='float32')\n",
    "                for i, (input_text, target_text) in enumerate(zip(X[j:j+batch_size], y[j:j+batch_size])):\n",
    "                    for t, item in enumerate(input_text.split()):\n",
    "                        try:\n",
    "                            encoder_input_data[i, t] = encoder_tokens[item]\n",
    "                        except Exception as e:\n",
    "                            print(\"Wrong word:\",item)\n",
    "                            print(\"Exception:\",e)\n",
    "                    for t, item in enumerate(target_text.split()):\n",
    "                        if t<len(target_text)-1:\n",
    "                            decoder_input_data[i, t] = decoder_tokens[item]\n",
    "                        if t>0:\n",
    "                            decoder_target_data[i, t - 1, decoder_tokens[item]] = 1.\n",
    "                yield ([encoder_input_data, decoder_input_data], decoder_target_data)\n",
    "                \n",
    "    def enc_dec_model(self, input_vocab_size, target_vocab_size, encoder_tokens, decoder_tokens, src_data_length, tar_data_length, n_units):\n",
    "        \n",
    "        #encoder\n",
    "        encoder_input = Input(shape = (None,))\n",
    "        encoder_emb =  Embedding(input_vocab_size, n_units, mask_zero = False)(encoder_input)\n",
    "        encoder_lstm = LSTM(n_units,return_state = True)\n",
    "        encoder_outputs,encode_h,encoder_c = encoder_lstm(encoder_emb)\n",
    "        encoder_states = [encode_h,encoder_c]\n",
    "        \n",
    "        #decoder\n",
    "        decoder_input = Input(shape = (None,))\n",
    "        decoder_emb_layer = Embedding(target_vocab_size, n_units, mask_zero = False)\n",
    "        decoder_emb = decoder_emb_layer(decoder_input)\n",
    "        decoder_lstm = LSTM(n_units,return_sequences=True,return_state = True)\n",
    "        decoder_out,decode_h,decoder_c = decoder_lstm(decoder_emb,initial_state = encoder_states)\n",
    "        decoder_dense = Dense(target_vocab_size,activation=\"softmax\")\n",
    "        decoder_out = decoder_dense(decoder_out)\n",
    "        self.model = Model([encoder_input,decoder_input],decoder_out)\n",
    "        #compile\n",
    "        self.model.compile(optimizer=\"rmsprop\",loss=\"categorical_crossentropy\",metrics=['acc'])\n",
    "        print(self.model.summary())\n",
    "        #fit\n",
    "        train_gen = self.generate_batch(self.X_train,self.Y_train,src_data_length,tar_data_length,encoder_tokens, decoder_tokens, target_vocab_size,self.batch_size)\n",
    "        test_gen = self.generate_batch(self.X_test,self.Y_test,src_data_length,tar_data_length,encoder_tokens, decoder_tokens, target_vocab_size,self.batch_size)\n",
    "        train_samples_steps = len(self.X_train) / self.batch_size\n",
    "        val_samples_steps = len(self.X_test) / self.batch_size\n",
    "                \n",
    "\n",
    "        self.model.fit(train_gen, steps_per_epoch = train_samples_steps, epochs=self.epochs, validation_data = test_gen, validation_steps = val_samples_steps)\n",
    "        \n",
    "        #eocoder setup\n",
    "        \n",
    "        self.encoder_model = Model(encoder_input, encoder_states)\n",
    "        \n",
    "        # Decoder setup\n",
    "        decoder_state_input_h = Input(shape=(n_units,))\n",
    "        decoder_state_input_c = Input(shape=(n_units,))\n",
    "        decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "        \n",
    "        dec_emb2 = decoder_emb_layer(decoder_input)\n",
    "        \n",
    "        decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=decoder_states_inputs)\n",
    "        decoder_states2 = [state_h2, state_c2]\n",
    "        decoder_outputs2 = decoder_dense(decoder_outputs2) # A dense softmax layer to generate prob dist. over the target vocabulary\n",
    "        \n",
    "        # Final decoder model\n",
    "        self.decoder_model = Model([decoder_input] + decoder_states_inputs,[decoder_outputs2] + decoder_states2)\n",
    "    \n",
    "    def save_model(self,model,model_file):\n",
    "        with open(model_file+'.json', 'w', encoding='utf8') as f:\n",
    "            f.write(model.to_json())\n",
    "        model.save_weights(model_file+'.h5')\n",
    "        \n",
    "    def save(self):\n",
    "        encoder_model_name = 'Encoder_Model'\n",
    "        self.save_model(self.encoder_model,encoder_model_name)\n",
    "        \n",
    "        decoder_model_name = 'Decoder_Model'\n",
    "        self.save_model(self.decoder_model,decoder_model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wRj78Ihxg-5y"
   },
   "outputs": [],
   "source": [
    "class Prediction():\n",
    "    \n",
    "    def __init__(self,input_token_index, target_token_index,reverse_target_index,src_data_length):\n",
    "        self.src_data_length = src_data_length\n",
    "        self.input_token_index = input_token_index\n",
    "        self.target_token_index = target_token_index\n",
    "        self.reverse_target_index = reverse_target_index\n",
    "    \n",
    "    def load_weights(self,model_filename, model_weights_filename):\n",
    "        with open(model_filename, 'r', encoding='utf8') as f:\n",
    "            model = model_from_json(f.read())\n",
    "        model.load_weights(model_weights_filename)\n",
    "        return model\n",
    "    \n",
    "    def load_model(self):\n",
    "        encoder_model_name = 'Encoder_Model'\n",
    "        decoder_model_name = 'Decoder_Model'\n",
    "        self.encoder_model = self.load_weights(encoder_model_name+'.json', encoder_model_name+'.h5')\n",
    "        self.decoder_model = self.load_weights(decoder_model_name+'.json', decoder_model_name+'.h5')\n",
    "    \n",
    "    def decode_sequence(self,input_seq):\n",
    "        # Encode the input as state vectors.\n",
    "        states_value = self.encoder_model.predict(input_seq)\n",
    "        # Generate empty target sequence of length 1.\n",
    "        target_seq = np.zeros((1,1))\n",
    "        # Populate the first character of target sequence with the start character.\n",
    "        target_seq[0, 0] = self.target_token_index['START']\n",
    "\n",
    "        # Sampling loop for a batch of sequences\n",
    "        # (to simplify, here we assume a batch of size 1).\n",
    "        stop_condition = False\n",
    "        decoded_sentence = ''\n",
    "        while not stop_condition:\n",
    "            output_tokens, h, c = self.decoder_model.predict([target_seq] + states_value)\n",
    "\n",
    "            # Sample a token\n",
    "            sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "            sampled_char = self.reverse_target_index[sampled_token_index]\n",
    "            if sampled_char!=\"END\":\n",
    "                decoded_sentence += ' '+sampled_char\n",
    "\n",
    "            # Exit condition: either hit max length\n",
    "            # or find stop character.\n",
    "            if (sampled_char == 'END' or len(decoded_sentence) > 50):\n",
    "                stop_condition = True\n",
    "\n",
    "            # Update the target sequence (of length 1).\n",
    "            target_seq = np.zeros((1,1))\n",
    "            target_seq[0, 0] = sampled_token_index\n",
    "\n",
    "            # Update states\n",
    "            states_value = [h, c]\n",
    "\n",
    "        return decoded_sentence\n",
    "\n",
    "    def decode(self,input_text):\n",
    "        encoder_input_data = np.zeros((1, self.src_data_length),dtype='float32')\n",
    "        for t, item in enumerate(input_text.split()):\n",
    "            encoder_input_data[0, t] = self.input_token_index[item]\n",
    "        decode_output = self.decode_sequence(encoder_input_data)\n",
    "        return decode_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vWFBRwC3QN46"
   },
   "source": [
    "Loading & preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "id": "DM_UthjoQJ-K",
    "outputId": "769447c8-9a32-45c9-b98c-fa9403e30f65"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Input  Target\n",
      "0   Go.    যাও।\n",
      "1   Go.    যান।\n",
      "2   Go.     যা।\n",
      "3  Run!  পালাও!\n",
      "4  Run!  পালান!\n",
      "(3480,) (870,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1686"
      ]
     },
     "execution_count": 57,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 32\n",
    "ld = LoadData()\n",
    "input_target,df = ld.load_data()\n",
    "\n",
    "print(df.head()) \n",
    "prp = PreProcessing()\n",
    "x_train, x_test, y_train, y_test = prp.tokenization(df)\n",
    "print(x_train.shape, x_test.shape)\n",
    "input_vocab_size = prp.input_vocab_size + 1\n",
    "target_vocab_size = prp.target_vocab_size + 1\n",
    "input_token_index = prp.input_token_index\n",
    "target_token_index = prp.target_token_index\n",
    "input_max_length = prp.input_max_length\n",
    "target_max_length = prp.target_max_length\n",
    "reverse_input_index = prp.reverse_input_index\n",
    "reverse_target_index = prp.reverse_target_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EX2W046FQwhk"
   },
   "source": [
    "Training & Model Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "OO4uEfhJQzhV",
    "outputId": "e7a88686-7a76-4b4f-894f-5f69e526fc2e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_15\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_25 (InputLayer)           [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_26 (InputLayer)           [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_18 (Embedding)        (None, None, 300)    858300      input_25[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_19 (Embedding)        (None, None, 300)    1062900     input_26[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_18 (LSTM)                  [(None, 300), (None, 721200      embedding_18[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lstm_19 (LSTM)                  [(None, None, 300),  721200      embedding_19[0][0]               \n",
      "                                                                 lstm_18[0][1]                    \n",
      "                                                                 lstm_18[0][2]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, None, 3543)   1066443     lstm_19[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 4,430,043\n",
      "Trainable params: 4,430,043\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "109/108 [==============================] - 7s 61ms/step - loss: 1.5769 - acc: 0.0598 - val_loss: 1.4334 - val_acc: 0.0616\n",
      "Epoch 2/100\n",
      "109/108 [==============================] - 5s 46ms/step - loss: 1.4039 - acc: 0.0639 - val_loss: 1.3991 - val_acc: 0.0627\n",
      "Epoch 3/100\n",
      "109/108 [==============================] - 5s 46ms/step - loss: 1.3156 - acc: 0.0689 - val_loss: 1.3604 - val_acc: 0.0695\n",
      "Epoch 4/100\n",
      "109/108 [==============================] - 5s 46ms/step - loss: 1.2450 - acc: 0.0729 - val_loss: 1.3450 - val_acc: 0.0709\n",
      "Epoch 5/100\n",
      "109/108 [==============================] - 5s 46ms/step - loss: 1.1786 - acc: 0.0779 - val_loss: 1.3150 - val_acc: 0.0739\n",
      "Epoch 6/100\n",
      "109/108 [==============================] - 5s 46ms/step - loss: 1.1194 - acc: 0.0832 - val_loss: 1.2998 - val_acc: 0.0755\n",
      "Epoch 7/100\n",
      "109/108 [==============================] - 5s 46ms/step - loss: 1.0630 - acc: 0.0892 - val_loss: 1.2800 - val_acc: 0.0782\n",
      "Epoch 8/100\n",
      "109/108 [==============================] - 5s 46ms/step - loss: 1.0065 - acc: 0.0950 - val_loss: 1.2620 - val_acc: 0.0822\n",
      "Epoch 9/100\n",
      "109/108 [==============================] - 5s 46ms/step - loss: 0.9546 - acc: 0.1002 - val_loss: 1.2410 - val_acc: 0.0860\n",
      "Epoch 10/100\n",
      "109/108 [==============================] - 5s 46ms/step - loss: 0.9038 - acc: 0.1068 - val_loss: 1.2321 - val_acc: 0.0873\n",
      "Epoch 11/100\n",
      "109/108 [==============================] - 5s 46ms/step - loss: 0.8575 - acc: 0.1115 - val_loss: 1.2120 - val_acc: 0.0906\n",
      "Epoch 12/100\n",
      "109/108 [==============================] - 5s 46ms/step - loss: 0.8130 - acc: 0.1173 - val_loss: 1.2015 - val_acc: 0.0925\n",
      "Epoch 13/100\n",
      "109/108 [==============================] - 5s 46ms/step - loss: 0.7712 - acc: 0.1234 - val_loss: 1.1757 - val_acc: 0.0967\n",
      "Epoch 14/100\n",
      "109/108 [==============================] - 5s 45ms/step - loss: 0.7317 - acc: 0.1289 - val_loss: 1.1736 - val_acc: 0.0970\n",
      "Epoch 15/100\n",
      "109/108 [==============================] - 5s 46ms/step - loss: 0.6946 - acc: 0.1358 - val_loss: 1.1592 - val_acc: 0.0987\n",
      "Epoch 16/100\n",
      "109/108 [==============================] - 5s 46ms/step - loss: 0.6609 - acc: 0.1410 - val_loss: 1.1455 - val_acc: 0.1037\n",
      "Epoch 17/100\n",
      "109/108 [==============================] - 5s 46ms/step - loss: 0.6259 - acc: 0.1472 - val_loss: 1.1369 - val_acc: 0.1038\n",
      "Epoch 18/100\n",
      "109/108 [==============================] - 5s 46ms/step - loss: 0.5962 - acc: 0.1521 - val_loss: 1.1381 - val_acc: 0.1038\n",
      "Epoch 19/100\n",
      "109/108 [==============================] - 5s 46ms/step - loss: 0.5681 - acc: 0.1583 - val_loss: 1.1275 - val_acc: 0.1066\n",
      "Epoch 20/100\n",
      "109/108 [==============================] - 5s 46ms/step - loss: 0.5375 - acc: 0.1639 - val_loss: 1.1112 - val_acc: 0.1089\n",
      "Epoch 21/100\n",
      "109/108 [==============================] - 5s 46ms/step - loss: 0.5071 - acc: 0.1690 - val_loss: 1.1210 - val_acc: 0.1089\n",
      "Epoch 22/100\n",
      "109/108 [==============================] - 5s 46ms/step - loss: 0.4784 - acc: 0.1749 - val_loss: 1.1014 - val_acc: 0.1114\n",
      "Epoch 23/100\n",
      "109/108 [==============================] - 5s 48ms/step - loss: 0.4508 - acc: 0.1797 - val_loss: 1.1025 - val_acc: 0.1129\n",
      "Epoch 24/100\n",
      "109/108 [==============================] - 5s 47ms/step - loss: 0.4253 - acc: 0.1852 - val_loss: 1.1004 - val_acc: 0.1121\n",
      "Epoch 25/100\n",
      "109/108 [==============================] - 5s 46ms/step - loss: 0.4039 - acc: 0.1892 - val_loss: 1.1071 - val_acc: 0.1125\n",
      "Epoch 26/100\n",
      "109/108 [==============================] - 5s 46ms/step - loss: 0.3822 - acc: 0.1941 - val_loss: 1.0954 - val_acc: 0.1137\n",
      "Epoch 27/100\n",
      "109/108 [==============================] - 5s 46ms/step - loss: 0.3575 - acc: 0.1990 - val_loss: 1.1025 - val_acc: 0.1147\n",
      "Epoch 28/100\n",
      "109/108 [==============================] - 5s 46ms/step - loss: 0.3350 - acc: 0.2046 - val_loss: 1.0908 - val_acc: 0.1176\n",
      "Epoch 29/100\n",
      "109/108 [==============================] - 5s 46ms/step - loss: 0.3144 - acc: 0.2076 - val_loss: 1.0927 - val_acc: 0.1175\n",
      "Epoch 30/100\n",
      "109/108 [==============================] - 5s 46ms/step - loss: 0.2967 - acc: 0.2120 - val_loss: 1.0941 - val_acc: 0.1174\n",
      "Epoch 31/100\n",
      "109/108 [==============================] - 5s 46ms/step - loss: 0.2815 - acc: 0.2147 - val_loss: 1.0780 - val_acc: 0.1185\n",
      "Epoch 32/100\n",
      "109/108 [==============================] - 5s 46ms/step - loss: 0.2687 - acc: 0.2176 - val_loss: 1.0728 - val_acc: 0.1195\n",
      "Epoch 33/100\n",
      "109/108 [==============================] - 5s 46ms/step - loss: 0.2553 - acc: 0.2203 - val_loss: 1.0840 - val_acc: 0.1209\n",
      "Epoch 34/100\n",
      "109/108 [==============================] - 5s 46ms/step - loss: 0.2415 - acc: 0.2226 - val_loss: 1.0750 - val_acc: 0.1222\n",
      "Epoch 35/100\n",
      "109/108 [==============================] - 5s 46ms/step - loss: 0.2261 - acc: 0.2258 - val_loss: 1.0775 - val_acc: 0.1218\n",
      "Epoch 36/100\n",
      "109/108 [==============================] - 5s 46ms/step - loss: 0.2111 - acc: 0.2290 - val_loss: 1.0792 - val_acc: 0.1222\n",
      "Epoch 37/100\n",
      "109/108 [==============================] - 5s 46ms/step - loss: 0.2016 - acc: 0.2308 - val_loss: 1.0765 - val_acc: 0.1219\n",
      "Epoch 38/100\n",
      "109/108 [==============================] - 5s 45ms/step - loss: 0.1903 - acc: 0.2329 - val_loss: 1.0821 - val_acc: 0.1229\n",
      "Epoch 39/100\n",
      "109/108 [==============================] - 5s 45ms/step - loss: 0.1790 - acc: 0.2352 - val_loss: 1.0809 - val_acc: 0.1244\n",
      "Epoch 40/100\n",
      "109/108 [==============================] - 5s 46ms/step - loss: 0.1699 - acc: 0.2369 - val_loss: 1.0860 - val_acc: 0.1228\n",
      "Epoch 41/100\n",
      "109/108 [==============================] - 5s 46ms/step - loss: 0.1589 - acc: 0.2393 - val_loss: 1.0834 - val_acc: 0.1242\n",
      "Epoch 42/100\n",
      "109/108 [==============================] - 5s 46ms/step - loss: 0.1509 - acc: 0.2403 - val_loss: 1.0942 - val_acc: 0.1238\n",
      "Epoch 43/100\n",
      "109/108 [==============================] - 5s 47ms/step - loss: 0.1441 - acc: 0.2415 - val_loss: 1.0827 - val_acc: 0.1242\n",
      "Epoch 44/100\n",
      "109/108 [==============================] - 5s 46ms/step - loss: 0.1365 - acc: 0.2421 - val_loss: 1.0921 - val_acc: 0.1254\n",
      "Epoch 45/100\n",
      "109/108 [==============================] - 5s 46ms/step - loss: 0.1285 - acc: 0.2434 - val_loss: 1.0909 - val_acc: 0.1262\n",
      "Epoch 46/100\n",
      "109/108 [==============================] - 5s 46ms/step - loss: 0.1192 - acc: 0.2455 - val_loss: 1.0942 - val_acc: 0.1267\n",
      "Epoch 47/100\n",
      "109/108 [==============================] - 5s 46ms/step - loss: 0.1119 - acc: 0.2473 - val_loss: 1.1048 - val_acc: 0.1246\n",
      "Epoch 48/100\n",
      "109/108 [==============================] - 5s 46ms/step - loss: 0.1056 - acc: 0.2480 - val_loss: 1.1067 - val_acc: 0.1258\n",
      "Epoch 49/100\n",
      "109/108 [==============================] - 5s 46ms/step - loss: 0.1014 - acc: 0.2490 - val_loss: 1.1025 - val_acc: 0.1259\n",
      "Epoch 50/100\n",
      "109/108 [==============================] - 5s 46ms/step - loss: 0.0983 - acc: 0.2498 - val_loss: 1.1117 - val_acc: 0.1261\n",
      "Epoch 51/100\n",
      "109/108 [==============================] - 5s 46ms/step - loss: 0.0964 - acc: 0.2499 - val_loss: 1.1030 - val_acc: 0.1266\n",
      "Epoch 52/100\n",
      "109/108 [==============================] - 5s 46ms/step - loss: 0.0899 - acc: 0.2505 - val_loss: 1.1076 - val_acc: 0.1267\n",
      "Epoch 53/100\n",
      "109/108 [==============================] - 5s 46ms/step - loss: 0.0858 - acc: 0.2514 - val_loss: 1.1075 - val_acc: 0.1259\n",
      "Epoch 54/100\n",
      "109/108 [==============================] - 5s 46ms/step - loss: 0.0833 - acc: 0.2520 - val_loss: 1.1095 - val_acc: 0.1257\n",
      "Epoch 55/100\n",
      "109/108 [==============================] - 5s 46ms/step - loss: 0.0822 - acc: 0.2518 - val_loss: 1.1106 - val_acc: 0.1270\n",
      "Epoch 56/100\n",
      "109/108 [==============================] - 5s 46ms/step - loss: 0.0847 - acc: 0.2512 - val_loss: 1.1160 - val_acc: 0.1262\n",
      "Epoch 57/100\n",
      "109/108 [==============================] - 5s 46ms/step - loss: 0.0802 - acc: 0.2519 - val_loss: 1.1174 - val_acc: 0.1276\n",
      "Epoch 58/100\n",
      "109/108 [==============================] - 5s 45ms/step - loss: 0.0749 - acc: 0.2531 - val_loss: 1.1133 - val_acc: 0.1276\n",
      "Epoch 59/100\n",
      "109/108 [==============================] - 5s 46ms/step - loss: 0.0699 - acc: 0.2539 - val_loss: 1.1221 - val_acc: 0.1268\n",
      "Epoch 60/100\n",
      "109/108 [==============================] - 5s 46ms/step - loss: 0.0658 - acc: 0.2549 - val_loss: 1.1300 - val_acc: 0.1261\n",
      "Epoch 61/100\n",
      "109/108 [==============================] - 5s 46ms/step - loss: 0.0649 - acc: 0.2544 - val_loss: 1.1234 - val_acc: 0.1265\n",
      "Epoch 62/100\n",
      "109/108 [==============================] - 5s 45ms/step - loss: 0.0604 - acc: 0.2554 - val_loss: 1.1311 - val_acc: 0.1275\n",
      "Epoch 63/100\n",
      "109/108 [==============================] - 5s 46ms/step - loss: 0.0613 - acc: 0.2551 - val_loss: 1.1264 - val_acc: 0.1276\n",
      "Epoch 64/100\n",
      "109/108 [==============================] - 5s 46ms/step - loss: 0.0613 - acc: 0.2550 - val_loss: 1.1344 - val_acc: 0.1273\n",
      "Epoch 65/100\n",
      "109/108 [==============================] - 5s 46ms/step - loss: 0.0584 - acc: 0.2553 - val_loss: 1.1277 - val_acc: 0.1270\n",
      "Epoch 66/100\n",
      "109/108 [==============================] - 5s 46ms/step - loss: 0.0578 - acc: 0.2553 - val_loss: 1.1325 - val_acc: 0.1284\n",
      "Epoch 67/100\n",
      "109/108 [==============================] - 5s 46ms/step - loss: 0.0581 - acc: 0.2550 - val_loss: 1.1302 - val_acc: 0.1276\n",
      "Epoch 68/100\n",
      "109/108 [==============================] - 5s 46ms/step - loss: 0.0554 - acc: 0.2551 - val_loss: 1.1343 - val_acc: 0.1275\n",
      "Epoch 69/100\n",
      "109/108 [==============================] - 5s 45ms/step - loss: 0.0536 - acc: 0.2560 - val_loss: 1.1335 - val_acc: 0.1282\n",
      "Epoch 70/100\n",
      "109/108 [==============================] - 5s 46ms/step - loss: 0.0516 - acc: 0.2560 - val_loss: 1.1295 - val_acc: 0.1285\n",
      "Epoch 71/100\n",
      "109/108 [==============================] - 5s 45ms/step - loss: 0.0490 - acc: 0.2569 - val_loss: 1.1435 - val_acc: 0.1280\n",
      "Epoch 72/100\n",
      "109/108 [==============================] - 5s 45ms/step - loss: 0.0488 - acc: 0.2566 - val_loss: 1.1405 - val_acc: 0.1276\n",
      "Epoch 73/100\n",
      "109/108 [==============================] - 5s 45ms/step - loss: 0.0469 - acc: 0.2575 - val_loss: 1.1436 - val_acc: 0.1287\n",
      "Epoch 74/100\n",
      "109/108 [==============================] - 5s 45ms/step - loss: 0.0465 - acc: 0.2576 - val_loss: 1.1375 - val_acc: 0.1283\n",
      "Epoch 75/100\n",
      "109/108 [==============================] - 5s 45ms/step - loss: 0.0445 - acc: 0.2576 - val_loss: 1.1361 - val_acc: 0.1280\n",
      "Epoch 76/100\n",
      "109/108 [==============================] - 5s 45ms/step - loss: 0.0441 - acc: 0.2583 - val_loss: 1.1452 - val_acc: 0.1296\n",
      "Epoch 77/100\n",
      "109/108 [==============================] - 5s 45ms/step - loss: 0.0432 - acc: 0.2582 - val_loss: 1.1440 - val_acc: 0.1283\n",
      "Epoch 78/100\n",
      "109/108 [==============================] - 5s 45ms/step - loss: 0.0420 - acc: 0.2581 - val_loss: 1.1501 - val_acc: 0.1291\n",
      "Epoch 79/100\n",
      "109/108 [==============================] - 5s 45ms/step - loss: 0.0422 - acc: 0.2584 - val_loss: 1.1474 - val_acc: 0.1285\n",
      "Epoch 80/100\n",
      "109/108 [==============================] - 5s 45ms/step - loss: 0.0423 - acc: 0.2584 - val_loss: 1.1418 - val_acc: 0.1295\n",
      "Epoch 81/100\n",
      "109/108 [==============================] - 5s 46ms/step - loss: 0.0432 - acc: 0.2577 - val_loss: 1.1488 - val_acc: 0.1284\n",
      "Epoch 82/100\n",
      "109/108 [==============================] - 5s 46ms/step - loss: 0.0433 - acc: 0.2574 - val_loss: 1.1513 - val_acc: 0.1286\n",
      "Epoch 83/100\n",
      "109/108 [==============================] - 5s 46ms/step - loss: 0.0436 - acc: 0.2574 - val_loss: 1.1512 - val_acc: 0.1292\n",
      "Epoch 84/100\n",
      "109/108 [==============================] - 5s 46ms/step - loss: 0.0411 - acc: 0.2576 - val_loss: 1.1597 - val_acc: 0.1294\n",
      "Epoch 85/100\n",
      "109/108 [==============================] - 5s 47ms/step - loss: 0.0401 - acc: 0.2581 - val_loss: 1.1631 - val_acc: 0.1292\n",
      "Epoch 86/100\n",
      "109/108 [==============================] - 5s 46ms/step - loss: 0.0386 - acc: 0.2583 - val_loss: 1.1652 - val_acc: 0.1291\n",
      "Epoch 87/100\n",
      "109/108 [==============================] - 5s 46ms/step - loss: 0.0390 - acc: 0.2585 - val_loss: 1.1673 - val_acc: 0.1287\n",
      "Epoch 88/100\n",
      "109/108 [==============================] - 5s 45ms/step - loss: 0.0376 - acc: 0.2585 - val_loss: 1.1735 - val_acc: 0.1300\n",
      "Epoch 89/100\n",
      "109/108 [==============================] - 5s 45ms/step - loss: 0.0373 - acc: 0.2586 - val_loss: 1.1710 - val_acc: 0.1290\n",
      "Epoch 90/100\n",
      "109/108 [==============================] - 5s 46ms/step - loss: 0.0379 - acc: 0.2587 - val_loss: 1.1721 - val_acc: 0.1297\n",
      "Epoch 91/100\n",
      "109/108 [==============================] - 5s 45ms/step - loss: 0.0371 - acc: 0.2590 - val_loss: 1.1757 - val_acc: 0.1283\n",
      "Epoch 92/100\n",
      "109/108 [==============================] - 5s 45ms/step - loss: 0.0361 - acc: 0.2589 - val_loss: 1.1797 - val_acc: 0.1302\n",
      "Epoch 93/100\n",
      "109/108 [==============================] - 5s 46ms/step - loss: 0.0358 - acc: 0.2591 - val_loss: 1.1839 - val_acc: 0.1294\n",
      "Epoch 94/100\n",
      "109/108 [==============================] - 5s 46ms/step - loss: 0.0351 - acc: 0.2591 - val_loss: 1.1909 - val_acc: 0.1278\n",
      "Epoch 95/100\n",
      "109/108 [==============================] - 5s 48ms/step - loss: 0.0330 - acc: 0.2593 - val_loss: 1.1869 - val_acc: 0.1289\n",
      "Epoch 96/100\n",
      "109/108 [==============================] - 5s 47ms/step - loss: 0.0350 - acc: 0.2590 - val_loss: 1.1786 - val_acc: 0.1285\n",
      "Epoch 97/100\n",
      "109/108 [==============================] - 5s 46ms/step - loss: 0.0361 - acc: 0.2586 - val_loss: 1.1799 - val_acc: 0.1283\n",
      "Epoch 98/100\n",
      "109/108 [==============================] - 5s 46ms/step - loss: 0.0350 - acc: 0.2589 - val_loss: 1.1810 - val_acc: 0.1286\n",
      "Epoch 99/100\n",
      "109/108 [==============================] - 5s 46ms/step - loss: 0.0332 - acc: 0.2596 - val_loss: 1.1817 - val_acc: 0.1289\n",
      "Epoch 100/100\n",
      "109/108 [==============================] - 5s 45ms/step - loss: 0.0323 - acc: 0.2596 - val_loss: 1.1861 - val_acc: 0.1288\n"
     ]
    }
   ],
   "source": [
    "model_obj = DesignModel(x_train,y_train,x_test,y_test,100,32)\n",
    "model_obj.enc_dec_model(input_vocab_size, target_vocab_size, input_token_index, target_token_index, input_max_length,target_max_length,300)\n",
    "model_obj.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Q-KhfOpUQ5PW"
   },
   "source": [
    "Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "4Fx71zjsQ6kN",
    "outputId": "894d9da5-429c-402d-d861-2b4c12865006"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoded sentence:  যা।\n"
     ]
    }
   ],
   "source": [
    "reverse_word_map = dict(map(reversed, target_tokenizer.word_index.items()))\n",
    "pred = Prediction(input_token_index, target_token_index,reverse_target_index,input_max_length)\n",
    "pred.load_model()\n",
    "decoded_sentence = pred.decode(\"Go.\")\n",
    "print('Decoded sentence:', decoded_sentence)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "seq2seq.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
