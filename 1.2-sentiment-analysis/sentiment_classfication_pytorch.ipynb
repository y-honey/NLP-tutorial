{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from nltk.corpus import stopwords \n",
    "from collections import Counter\n",
    "import string\n",
    "import re\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU not available, CPU used\n"
     ]
    }
   ],
   "source": [
    "is_cuda = torch.cuda.is_available()\n",
    "\n",
    "# If we have a GPU available, we'll set our device to GPU. We'll use this device variable later in our code.\n",
    "if is_cuda:\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"GPU is available\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"GPU not available, CPU used\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"imdb_dataset_small.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of train data is (15000,)\n",
      "shape of test data is (5000,)\n"
     ]
    }
   ],
   "source": [
    "X,y = df['review'].values,df['sentiment'].values\n",
    "x_train,x_test,y_train,y_test = train_test_split(X,y,stratify=y)\n",
    "print(f'shape of train data is {x_train.shape}')\n",
    "print(f'shape of test data is {x_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_string(s):\n",
    "    # Remove all non-word characters (everything except numbers and letters)\n",
    "    s = re.sub(r\"[^\\w\\s]\", '', s)\n",
    "    # Replace all runs of whitespaces with no space\n",
    "    s = re.sub(r\"\\s+\", '', s)\n",
    "    # replace digits with no space\n",
    "    s = re.sub(r\"\\d\", '', s)\n",
    "\n",
    "    return s\n",
    "\n",
    "def tockenize(x_train,y_train,x_val,y_val):\n",
    "    word_list = []\n",
    "\n",
    "    stop_words = set(stopwords.words('english')) \n",
    "    for sent in x_train:\n",
    "        for word in sent.lower().split():\n",
    "            word = preprocess_string(word)\n",
    "            if word not in stop_words and word != '':\n",
    "                word_list.append(word)\n",
    "  \n",
    "    corpus = Counter(word_list)\n",
    "    # sorting on the basis of most common words\n",
    "    corpus_ = sorted(corpus,key=corpus.get,reverse=True)[:1000]\n",
    "    # creating a dict\n",
    "    onehot_dict = {w:i+1 for i,w in enumerate(corpus_)}\n",
    "    \n",
    "    # tockenize\n",
    "    final_list_train,final_list_test = [],[]\n",
    "    for sent in x_train:\n",
    "            final_list_train.append([onehot_dict[preprocess_string(word)] for word in sent.lower().split() \n",
    "                                     if preprocess_string(word) in onehot_dict.keys()])\n",
    "    for sent in x_val:\n",
    "            final_list_test.append([onehot_dict[preprocess_string(word)] for word in sent.lower().split() \n",
    "                                    if preprocess_string(word) in onehot_dict.keys()])\n",
    "            \n",
    "    encoded_train = [1 if label =='positive' else 0 for label in y_train]  \n",
    "    encoded_test = [1 if label =='positive' else 0 for label in y_val] \n",
    "    return np.array(final_list_train), np.array(encoded_train),np.array(final_list_test), np.array(encoded_test),onehot_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of vocabulary is 1000\n"
     ]
    }
   ],
   "source": [
    "x_train,y_train,x_test,y_test,vocab = tockenize(x_train,y_train,x_test,y_test)\n",
    "print(f'Length of vocabulary is {len(vocab)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "count    15000.000000\n",
       "mean        69.404133\n",
       "std         47.926500\n",
       "min          4.000000\n",
       "25%         39.000000\n",
       "50%         54.000000\n",
       "75%         85.000000\n",
       "max        452.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rev_len = [len(i) for i in x_train]\n",
    "pd.Series(rev_len).hist()\n",
    "plt.show()\n",
    "pd.Series(rev_len).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def padding_(sentences, seq_len):\n",
    "    features = np.zeros((len(sentences), seq_len),dtype=int)\n",
    "    for ii, review in enumerate(sentences):\n",
    "        if len(review) != 0:\n",
    "            features[ii, -len(review):] = np.array(review)[:seq_len]\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we have very less number of reviews with length > 500.\n",
    "#So we will consideronly those below it.\n",
    "x_train_pad = padding_(x_train,500)\n",
    "x_test_pad = padding_(x_test,500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample input size:  torch.Size([50, 500])\n",
      "Sample input: \n",
      " tensor([[  0,   0,   0,  ..., 695, 101, 504],\n",
      "        [  0,   0,   0,  ...,   4, 364, 521],\n",
      "        [  0,   0,   0,  ..., 820, 262, 218],\n",
      "        ...,\n",
      "        [  0,   0,   0,  ..., 368, 587, 148],\n",
      "        [  0,   0,   0,  ..., 746,   1, 530],\n",
      "        [  0,   0,   0,  ..., 524,  45, 237]])\n",
      "Sample input: \n",
      " tensor([0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1,\n",
      "        0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0,\n",
      "        0, 0])\n"
     ]
    }
   ],
   "source": [
    "# create Tensor datasets\n",
    "train_data = TensorDataset(torch.from_numpy(x_train_pad), torch.from_numpy(y_train))\n",
    "valid_data = TensorDataset(torch.from_numpy(x_test_pad), torch.from_numpy(y_test))\n",
    "\n",
    "# dataloaders\n",
    "batch_size = 50\n",
    "\n",
    "# make sure to SHUFFLE your data\n",
    "train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size)\n",
    "valid_loader = DataLoader(valid_data, shuffle=True, batch_size=batch_size)\n",
    "# obtain one batch of training data\n",
    "dataiter = iter(train_loader)\n",
    "sample_x, sample_y = dataiter.next()\n",
    "\n",
    "print('Sample input size: ', sample_x.size()) # batch_size, seq_length\n",
    "print('Sample input: \\n', sample_x)\n",
    "print('Sample input: \\n', sample_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentRNN(nn.Module):\n",
    "    def __init__(self,no_layers,vocab_size,hidden_dim,embedding_dim,drop_prob=0.5):\n",
    "        super(SentimentRNN,self).__init__()\n",
    " \n",
    "        self.output_dim = output_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    " \n",
    "        self.no_layers = no_layers\n",
    "        self.vocab_size = vocab_size\n",
    "    \n",
    "        # embedding and LSTM layers\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        \n",
    "        #lstm\n",
    "        self.lstm = nn.LSTM(input_size=embedding_dim,hidden_size=self.hidden_dim,\n",
    "                           num_layers=no_layers, batch_first=True)\n",
    "        \n",
    "        \n",
    "        # dropout layer\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "    \n",
    "        # linear and sigmoid layer\n",
    "        self.fc = nn.Linear(self.hidden_dim, output_dim)\n",
    "        self.sig = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self,x,hidden):\n",
    "        batch_size = x.size(0)\n",
    "        # embeddings and lstm_out\n",
    "        embeds = self.embedding(x)  # shape: B x S x Feature   since batch = True\n",
    "        #print(embeds.shape)  #[50, 500, 1000]\n",
    "        lstm_out, hidden = self.lstm(embeds, hidden)\n",
    "        \n",
    "        lstm_out = lstm_out.contiguous().view(-1, self.hidden_dim) \n",
    "        \n",
    "        # dropout and fully connected layer\n",
    "        out = self.dropout(lstm_out)\n",
    "        out = self.fc(out)\n",
    "        \n",
    "        # sigmoid function\n",
    "        sig_out = self.sig(out)\n",
    "        \n",
    "        # reshape to be batch_size first\n",
    "        sig_out = sig_out.view(batch_size, -1)\n",
    "\n",
    "        sig_out = sig_out[:, -1] # get last batch of labels\n",
    "        \n",
    "        # return last sigmoid output and hidden state\n",
    "        return sig_out, hidden\n",
    "        \n",
    "        \n",
    "        \n",
    "    def init_hidden(self, batch_size):\n",
    "        ''' Initializes hidden state '''\n",
    "        # Create two new tensors with sizes n_layers x batch_size x hidden_dim,\n",
    "        # initialized to zero, for hidden state and cell state of LSTM\n",
    "        h0 = torch.zeros((self.no_layers,batch_size,self.hidden_dim)).to(device)\n",
    "        c0 = torch.zeros((self.no_layers,batch_size,self.hidden_dim)).to(device)\n",
    "        hidden = (h0,c0)\n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SentimentRNN(\n",
      "  (embedding): Embedding(1001, 64)\n",
      "  (lstm): LSTM(64, 256, num_layers=2, batch_first=True)\n",
      "  (dropout): Dropout(p=0.3, inplace=False)\n",
      "  (fc): Linear(in_features=256, out_features=1, bias=True)\n",
      "  (sig): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "no_layers = 2\n",
    "vocab_size = len(vocab) + 1 #extra 1 for padding\n",
    "embedding_dim = 64\n",
    "output_dim = 1\n",
    "hidden_dim = 256\n",
    "\n",
    "\n",
    "model = SentimentRNN(no_layers,vocab_size,hidden_dim,embedding_dim,drop_prob=0.5)\n",
    "\n",
    "#moving to gpu\n",
    "model.to(device)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss and optimization functions\n",
    "lr=0.001\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "# function to predict accuracy\n",
    "def acc(pred,label):\n",
    "    pred = torch.round(pred.squeeze())\n",
    "    return torch.sum(pred == label.squeeze()).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clip = 5\n",
    "epochs = 5 \n",
    "valid_loss_min = np.Inf\n",
    "# train for some number of epochs\n",
    "epoch_tr_loss,epoch_vl_loss = [],[]\n",
    "epoch_tr_acc,epoch_vl_acc = [],[]\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_losses = []\n",
    "    train_acc = 0.0\n",
    "    model.train()\n",
    "    # initialize hidden state \n",
    "    h = model.init_hidden(batch_size)\n",
    "    for inputs, labels in train_loader:\n",
    "        \n",
    "        inputs, labels = inputs.to(device), labels.to(device)   \n",
    "        # Creating new variables for the hidden state, otherwise\n",
    "        # we'd backprop through the entire training history\n",
    "        h = tuple([each.data for each in h])\n",
    "        \n",
    "        model.zero_grad()\n",
    "        output,h = model(inputs,h)\n",
    "        \n",
    "        # calculate the loss and perform backprop\n",
    "        loss = criterion(output.squeeze(), labels.float())\n",
    "        loss.backward()\n",
    "        train_losses.append(loss.item())\n",
    "        # calculating accuracy\n",
    "        accuracy = acc(output,labels)\n",
    "        train_acc += accuracy\n",
    "        #`clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        optimizer.step()\n",
    " \n",
    "    \n",
    "        \n",
    "    val_h = model.init_hidden(batch_size)\n",
    "    val_losses = []\n",
    "    val_acc = 0.0\n",
    "    model.eval()\n",
    "    for inputs, labels in valid_loader:\n",
    "            val_h = tuple([each.data for each in val_h])\n",
    "\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            output, val_h = model(inputs, val_h)\n",
    "            val_loss = criterion(output.squeeze(), labels.float())\n",
    "\n",
    "            val_losses.append(val_loss.item())\n",
    "            \n",
    "            accuracy = acc(output,labels)\n",
    "            val_acc += accuracy\n",
    "            \n",
    "    epoch_train_loss = np.mean(train_losses)\n",
    "    epoch_val_loss = np.mean(val_losses)\n",
    "    epoch_train_acc = train_acc/len(train_loader.dataset)\n",
    "    epoch_val_acc = val_acc/len(valid_loader.dataset)\n",
    "    epoch_tr_loss.append(epoch_train_loss)\n",
    "    epoch_vl_loss.append(epoch_val_loss)\n",
    "    epoch_tr_acc.append(epoch_train_acc)\n",
    "    epoch_vl_acc.append(epoch_val_acc)\n",
    "    print(f'Epoch {epoch+1}') \n",
    "    print(f'train_loss : {epoch_train_loss} val_loss : {epoch_val_loss}')\n",
    "    print(f'train_accuracy : {epoch_train_acc*100} val_accuracy : {epoch_val_acc*100}')\n",
    "    if epoch_val_loss <= valid_loss_min:\n",
    "        torch.save(model.state_dict(), '../working/state_dict.pt')\n",
    "        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(valid_loss_min,epoch_val_loss))\n",
    "        valid_loss_min = epoch_val_loss\n",
    "    print(25*'==')\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (20, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epoch_tr_acc, label='Train Acc')\n",
    "plt.plot(epoch_vl_acc, label='Validation Acc')\n",
    "plt.title(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "    \n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epoch_tr_loss, label='Train loss')\n",
    "plt.plot(epoch_vl_loss, label='Validation loss')\n",
    "plt.title(\"Loss\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_text(text):\n",
    "        word_seq = np.array([vocab[preprocess_string(word)] for word in text.split() \n",
    "                         if preprocess_string(word) in vocab.keys()])\n",
    "        word_seq = np.expand_dims(word_seq,axis=0)\n",
    "        pad =  torch.from_numpy(padding_(word_seq,500))\n",
    "        inputs = pad.to(device)\n",
    "        batch_size = 1\n",
    "        h = model.init_hidden(batch_size)\n",
    "        h = tuple([each.data for each in h])\n",
    "        output, h = model(inputs, h)\n",
    "        return(output.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 30\n",
    "print(df['review'][index])\n",
    "print('='*70)\n",
    "print(f'Actual sentiment is  : {df[\"sentiment\"][index]}')\n",
    "print('='*70)\n",
    "pro = predict_text(df['review'][index])\n",
    "status = \"positive\" if pro > 0.5 else \"negative\"\n",
    "pro = (1 - pro) if status == \"negative\" else pro\n",
    "print(f'Predicted sentiment is {status} with a probability of {pro}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 32\n",
    "print(df['review'][index])\n",
    "print('='*70)\n",
    "print(f'Actual sentiment is  : {df[\"sentiment\"][index]}')\n",
    "print('='*70)\n",
    "pro = predict_text(df['review'][index])\n",
    "status = \"positive\" if pro > 0.5 else \"negative\"\n",
    "pro = (1 - pro) if status == \"negative\" else pro\n",
    "print(f'predicted sentiment is {status} with a probability of {pro}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
