{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import array\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Embedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'compile'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-ccc994e76514>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlang_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefine_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlang_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-ccc994e76514>\u001b[0m in \u001b[0;36mcreate_model\u001b[0;34m(self, model)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;31m# compile network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m         \u001b[0;31m# fit network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'compile'"
     ]
    }
   ],
   "source": [
    "class language_model():\n",
    "    def __init__(self,data,params):\n",
    "        self.data = data\n",
    "        self.model = None\n",
    "        self.tokenizer = None\n",
    "        self.max_length = None\n",
    "        self.epochs = params['epochs']\n",
    "        self.verbose = params[\"verbose\"]\n",
    "        self.x = None\n",
    "        self.y = None\n",
    "        \n",
    "    def preprocessing():\n",
    "        # integer encode sequences of words\n",
    "        self.tokenizer = Tokenizer()\n",
    "        self.tokenizer.fit_on_texts([data])\n",
    "        encoded = self.tokenizer.texts_to_sequences([data])[0]\n",
    "        \n",
    "        # retrieve vocabulary size\n",
    "        vocab_size = len(self.tokenizer.word_index) + 1\n",
    "        print('Vocabulary Size: %d' % vocab_size)\n",
    "        # encode 2 words -> 1 word\n",
    "        sequences = list()\n",
    "        for i in range(2, len(encoded)):\n",
    "            sequence = encoded[i-2:i+1]\n",
    "            sequences.append(sequence)\n",
    "        print('Total Sequences: %d' % len(sequences))\n",
    "        # pad sequences\n",
    "        self.max_length = max([len(seq) for seq in sequences])\n",
    "        sequences = pad_sequences(sequences, maxlen=self.max_length, padding='pre')\n",
    "        print('Max Sequence Length: %d' % self.max_length)\n",
    "        # split into input and output elements\n",
    "        sequences = array(sequences)\n",
    "        X, y = sequences[:,:-1],sequences[:,-1]\n",
    "        y = to_categorical(y, num_classes=vocab_size)\n",
    "        \n",
    "    def define_model(self):\n",
    "        model = Sequential()\n",
    "        model.add(Embedding(vocab_size, 10, input_length=max_length-1))\n",
    "        model.add(LSTM(50))\n",
    "        model.add(Dense(vocab_size, activation='softmax'))\n",
    "        model = self.model\n",
    "        return model\n",
    "    \n",
    "    def create_model(self):\n",
    "        # compile network\n",
    "        model = self.model\n",
    "        model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "        # fit network\n",
    "        model.fit(self.x, self.y, epochs=self.epochs, verbose=self.verbose)\n",
    "        return model\n",
    "    \n",
    "    # generate a sequence from a language model\n",
    "    def generate_seq(seed_text, n_words):\n",
    "        self.max_length = self.max_length-1\n",
    "        in_text = seed_text\n",
    "        # generate a fiselxed number of words\n",
    "        for _ in range(n_words):\n",
    "            # encode the text as integer\n",
    "            encoded = self.tokenizer.texts_to_sequences([in_text])[0]\n",
    "            # pre-pad sequences to a fixed length\n",
    "            encoded = pad_sequences([encoded], maxlen=self.max_length, padding='pre')\n",
    "            # predict probabilities for each word\n",
    "            yhat = self.model.predict_classes(encoded, verbose=0)\n",
    "            # map predicted word index to word\n",
    "            out_word = ''\n",
    "            for word, index in self.tokenizer.word_index.items():\n",
    "                if index == yhat:\n",
    "                    out_word = word\n",
    "                    break\n",
    "            # append to input\n",
    "            in_text += ' ' + out_word\n",
    "        return in_text\n",
    "\n",
    "# source text\n",
    "data = \"\"\" Jack and Jill went up the hill\\n\n",
    "        To fetch a pail of water\\n\n",
    "        Jack fell down and broke his crown\\n\n",
    "        And Jill came tumbling after\\n \"\"\"\n",
    "\n",
    "params = {\"activation\":\"softmax\",\"epochs\":500,\"verbose\":2}\n",
    "\n",
    "\n",
    "lang_model = language_model(data,params)\n",
    "\n",
    "model = lang_model.define_model()\n",
    "model = lang_model.create_model(model)\n",
    "\n",
    "\n",
    "\n",
    "# define model\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "# evaluate model\n",
    "print(generate_seq('Jack and', 5))\n",
    "print(generate_seq('And Jill', 3))\n",
    "print(generate_seq('fell down', 5))\n",
    "print(generate_seq('pail of', 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
