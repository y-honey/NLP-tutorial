{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Language Model Using Tensorflow & keras<h1> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>Importing Libraries<h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joydeb/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/joydeb/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/joydeb/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/joydeb/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/joydeb/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/joydeb/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/joydeb/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/joydeb/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/joydeb/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/joydeb/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/joydeb/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/joydeb/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.14.0\n"
     ]
    }
   ],
   "source": [
    "from numpy import array\n",
    "import tensorflow as tf\n",
    "print(tf.version.VERSION)\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>Preprocessing Data<h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoded: [[2, 1, 3, 4, 5, 6, 7], [8, 9, 10, 11, 12, 13], [2, 14, 15, 1, 16, 17, 18], [1, 3, 19, 20, 21]]\n",
      "Data: ['Jack and Jill went up the hill', 'To fetch a pail of water', 'Jack fell down and broke his crown', 'And Jill came tumbling after']\n",
      "sequences: [[ 2  1  3]\n",
      " [ 1  3  4]\n",
      " [ 3  4  5]\n",
      " [ 4  5  6]\n",
      " [ 5  6  7]\n",
      " [ 8  9 10]\n",
      " [ 9 10 11]\n",
      " [10 11 12]\n",
      " [11 12 13]\n",
      " [ 2 14 15]\n",
      " [14 15  1]\n",
      " [15  1 16]\n",
      " [ 1 16 17]\n",
      " [16 17 18]\n",
      " [ 1  3 19]\n",
      " [ 3 19 20]\n",
      " [19 20 21]]\n",
      "X: [[ 2  1]\n",
      " [ 1  3]\n",
      " [ 3  4]\n",
      " [ 4  5]\n",
      " [ 5  6]\n",
      " [ 8  9]\n",
      " [ 9 10]\n",
      " [10 11]\n",
      " [11 12]\n",
      " [ 2 14]\n",
      " [14 15]\n",
      " [15  1]\n",
      " [ 1 16]\n",
      " [16 17]\n",
      " [ 1  3]\n",
      " [ 3 19]\n",
      " [19 20]]\n",
      "Y: [[0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "class Preprocessing():\n",
    "    \n",
    "    def __init__(self,input_file):\n",
    "        self.input_data_file = input_file\n",
    "        self.data = None\n",
    "        self.vocab_size = None\n",
    "        self.encoded_data = None\n",
    "        self.max_length = None\n",
    "        self.seq_len = 3\n",
    "        self.sequences = None\n",
    "        self.x = None\n",
    "        self.y = None\n",
    "    \n",
    "    def load_data(self):\n",
    "        fp = open(self.input_data_file,'r')\n",
    "        self.data = fp.read().splitlines()        \n",
    "        fp.close()\n",
    "        \n",
    "    def encode_data(self):\n",
    "        tokenizer = Tokenizer()\n",
    "        tokenizer.fit_on_texts(self.data)\n",
    "        self.encoded_data = tokenizer.texts_to_sequences(self.data)\n",
    "        self.vocab_size = len(tokenizer.word_counts)+1\n",
    "        print(\"encoded: {}\".format(self.encoded_data))\n",
    "        print(\"Data: {}\".format(self.data))\n",
    "    def get_sequence(self):\n",
    "        seq_list = list()\n",
    "        for item in self.encoded_data:\n",
    "            l = len(item)\n",
    "            stop_len = l-self.seq_len+1\n",
    "            for id in range(stop_len):\n",
    "                seq_list.append(item[id:id+self.seq_len])\n",
    "        \n",
    "        self.max_length = max([len(seq) for seq in seq_list])\n",
    "        self.sequences = pad_sequences(seq_list, maxlen=self.max_length, padding='pre')\n",
    "        self.sequences = array(self.sequences)\n",
    "        print(\"sequences: {}\".format(self.sequences))\n",
    "            \n",
    "    def get_data(self):\n",
    "        self.x = self.sequences[:,:-1]\n",
    "        self.y = self.sequences[:,-1]\n",
    "        self.y = to_categorical(self.y,num_classes=self.vocab_size)\n",
    "        print(\"X: {}\".format(self.x))\n",
    "        print(\"Y: {}\".format(self.y))\n",
    "pr = Preprocessing('data.txt')\n",
    "pr.load_data()\n",
    "pr.encode_data()\n",
    "pr.get_sequence()\n",
    "pr.get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data: [' Jack and Jill went up the hill\\n\\n        To fetch a pail of water\\n\\n        Jack fell down and broke his crown\\n\\n        And Jill came tumbling after\\n ']\n",
      "Vocabulary Size: 22\n",
      "Total Sequences: 23\n",
      "encoded: [2, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 2, 14, 15, 1, 16, 17, 18, 1, 3, 19, 20, 21]\n",
      "sequences: [[2, 1, 3], [1, 3, 4], [3, 4, 5], [4, 5, 6], [5, 6, 7], [6, 7, 8], [7, 8, 9], [8, 9, 10], [9, 10, 11], [10, 11, 12], [11, 12, 13], [12, 13, 2], [13, 2, 14], [2, 14, 15], [14, 15, 1], [15, 1, 16], [1, 16, 17], [16, 17, 18], [17, 18, 1], [18, 1, 3], [1, 3, 19], [3, 19, 20], [19, 20, 21]]\n",
      "Max Sequence Length: 3\n",
      "X: [[ 2  1]\n",
      " [ 1  3]\n",
      " [ 3  4]\n",
      " [ 4  5]\n",
      " [ 5  6]\n",
      " [ 6  7]\n",
      " [ 7  8]\n",
      " [ 8  9]\n",
      " [ 9 10]\n",
      " [10 11]\n",
      " [11 12]\n",
      " [12 13]\n",
      " [13  2]\n",
      " [ 2 14]\n",
      " [14 15]\n",
      " [15  1]\n",
      " [ 1 16]\n",
      " [16 17]\n",
      " [17 18]\n",
      " [18  1]\n",
      " [ 1  3]\n",
      " [ 3 19]\n",
      " [19 20]]\n",
      "Y: [[0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'summary'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-f8f861c87dfd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;31m# define model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlang_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;31m# evaluate model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'summary'"
     ]
    }
   ],
   "source": [
    "class language_model():\n",
    "    def __init__(self,data,params):\n",
    "        self.data = data\n",
    "        self.model = None\n",
    "        self.tokenizer = None\n",
    "        self.max_length = None\n",
    "        self.params = params\n",
    "        self.x = None\n",
    "        self.y = None\n",
    "        self.voacb_size = None\n",
    "        \n",
    "    def preprocessing(self):\n",
    "        \n",
    "        # integer encode sequences of words\n",
    "        self.tokenizer = Tokenizer()\n",
    "        self.tokenizer.fit_on_texts([data])\n",
    "        print(\"Data: {}\".format([data]))\n",
    "        encoded = self.tokenizer.texts_to_sequences([data])[0]\n",
    "        \n",
    "        # retrieve vocabulary size\n",
    "        self.vocab_size = len(self.tokenizer.word_index) + 1\n",
    "        \n",
    "        print('Vocabulary Size: %d' % self.vocab_size)\n",
    "        \n",
    "        # encode 2 words -> 1 word\n",
    "        sequences = list()\n",
    "        for i in range(2, len(encoded)):\n",
    "            sequence = encoded[i-2:i+1]\n",
    "            sequences.append(sequence)\n",
    "        print('Total Sequences: %d' % len(sequences))\n",
    "        print(\"encoded: {}\".format(encoded))\n",
    "        print(\"sequences: {}\".format(sequences))\n",
    "        \n",
    "        # pad sequences\n",
    "        self.max_length = max([len(seq) for seq in sequences])\n",
    "        sequences = pad_sequences(sequences, maxlen=self.max_length, padding='pre')\n",
    "        print('Max Sequence Length: %d' % self.max_length)\n",
    "        \n",
    "        # split into input and output elements\n",
    "        sequences = array(sequences)\n",
    "        self.x, self.y = sequences[:,:-1],sequences[:,-1]\n",
    "        self.y = to_categorical(self.y, num_classes=self.vocab_size)\n",
    "        print(\"X: {}\".format(self.x))\n",
    "        print(\"Y: {}\".format(self.y))\n",
    "        \n",
    "    def define_model(self):\n",
    "        self.model = Sequential()\n",
    "        self.model.add(Embedding(self.vocab_size, 10, input_length=self.max_length-1))\n",
    "        self.model.add(LSTM(50))\n",
    "        self.model.add(Dense(self.vocab_size, activation=self.params[\"activation\"]))\n",
    "    \n",
    "    def create_model(self):\n",
    "        # compile network\n",
    "        self.model.compile(loss='categorical_crossentropy', optimizer=self.params['optimizer'], \n",
    "                           metrics=self.params[\"metrics\"])\n",
    "        # fit network\n",
    "        self.model.fit(self.x, self.y, epochs=self.params[\"epochs\"], verbose=self.params[\"verbose\"])\n",
    "    \n",
    "    # generate a sequence from a language model\n",
    "    def generate_seq(self,seed_text, n_words):\n",
    "        in_text = seed_text\n",
    "        # generate a fiselxed number of words\n",
    "        for _ in range(n_words):\n",
    "            # encode the text as integer\n",
    "            encoded = self.tokenizer.texts_to_sequences([in_text])[0]\n",
    "            # pre-pad sequences to a fixed length\n",
    "            encoded = pad_sequences([encoded], maxlen=self.max_length-1, padding='pre')\n",
    "            # predict probabilities for each word\n",
    "            yhat = self.model.predict_classes(encoded, verbose=0)\n",
    "            # map predicted word index to word\n",
    "            out_word = ''\n",
    "            for word, index in self.tokenizer.word_index.items():\n",
    "                if index == yhat:\n",
    "                    out_word = word\n",
    "                    break\n",
    "            # append to input\n",
    "            in_text += ' ' + out_word\n",
    "        return in_text\n",
    "\n",
    "# source text\n",
    "data = \"\"\" Jack and Jill went up the hill\\n\n",
    "        To fetch a pail of water\\n\n",
    "        Jack fell down and broke his crown\\n\n",
    "        And Jill came tumbling after\\n \"\"\"\n",
    "\n",
    "params = {\"activation\":\"softmax\",\"epochs\":500,\"verbose\":2,\"loss\":\"categorical_crossentropy\",\n",
    "          \"optimizer\":\"adam\",\"metrics\":['accuracy']}\n",
    "\n",
    "\n",
    "lang_model = language_model(data,params)\n",
    "lang_model.preprocessing()\n",
    "#lang_model.define_model()\n",
    "#lang_model.create_model()\n",
    "\n",
    "# define model\n",
    "\n",
    "print(lang_model.model.summary())\n",
    "\n",
    "# evaluate model\n",
    "print(lang_model.generate_seq('Jack and', 5))\n",
    "print(lang_model.generate_seq('And Jill', 3))\n",
    "print(lang_model.generate_seq('fell down', 5))\n",
    "print(lang_model.generate_seq('pail of', 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
